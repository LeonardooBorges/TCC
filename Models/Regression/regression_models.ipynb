{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "Features = rates from selected diseases (FeatureSelection) + suicide rate \n",
    "\n",
    "Target = suicide rate of the following year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from skopt import gp_minimize\n",
    "import time\n",
    "import glob\n",
    "root = \"../../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_uf_cod = {11: 'RO',\n",
    "12: 'AC',\n",
    "13: 'AM',\n",
    "14: 'RR',\n",
    "15: 'PA',\n",
    "16: 'AP',\n",
    "17: 'TO',\n",
    "21: 'MA',\n",
    "22: 'PI',\n",
    "23: 'CE',\n",
    "24: 'RN',\n",
    "25: 'PB',\n",
    "26: 'PE',\n",
    "27: 'AL',\n",
    "28: 'SE',\n",
    "29: 'BA',\n",
    "31: 'MG',\n",
    "32: 'ES',\n",
    "33: 'RJ',\n",
    "35: 'SP',\n",
    "41: 'PR',\n",
    "42: 'SC',\n",
    "43: 'RS',\n",
    "50: 'MS',\n",
    "51: 'MT',\n",
    "52: 'GO',\n",
    "53: 'DF'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313  diseases\n"
     ]
    }
   ],
   "source": [
    "disease = \"\"\n",
    "path = root + \"CSV/TabNet/Internacoes_Rate/\"\n",
    "all_files = glob.glob(path + \"*.csv\")\n",
    "suicide = pd.read_csv(root +'CSV/Suicide/suicide_rates_08_18.csv', index_col=0)\n",
    "\n",
    "years = [str(x).zfill(2) for x in range(8,19)]\n",
    "columns = [\"RATE_\" + year for year in years]\n",
    "columns.append(\"MUNCOD\")\n",
    "\n",
    "disease_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    file_name = file.split(\"\\\\\")[-1]\n",
    "    disease = file_name.split(\".csv\")[0]\n",
    "    disease_df = pd.read_csv(file, sep=',', index_col=0)\n",
    "    if(set(disease_df.columns) == set(columns)):\n",
    "        disease_list.append(disease)\n",
    "print(len(disease_list), \" diseases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÚLCERA_GÁSTRICA_E_DUODENAL</th>\n",
       "      <th>MUNCOD</th>\n",
       "      <th>VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES</th>\n",
       "      <th>VARICELA_E_HERPES_ZOSTER</th>\n",
       "      <th>UROLITÍASE</th>\n",
       "      <th>TÉTANO_NEONATAL</th>\n",
       "      <th>TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS</th>\n",
       "      <th>TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES</th>\n",
       "      <th>TUBERCULOSE_PULMONAR</th>\n",
       "      <th>TUBERCULOSE_MILIAR</th>\n",
       "      <th>...</th>\n",
       "      <th>ANCILOSTOMÍASE</th>\n",
       "      <th>AMEBÍASE</th>\n",
       "      <th>ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO</th>\n",
       "      <th>AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL</th>\n",
       "      <th>ABORTO_POR_RAZÕES_MÉDICAS</th>\n",
       "      <th>ABORTO_ESPONTÂNEO</th>\n",
       "      <th>PREVIOUS</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.481914</td>\n",
       "      <td>110001</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142.409570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.757293</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>32.550759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.134191</td>\n",
       "      <td>20.344224</td>\n",
       "      <td>8.212203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.458389</td>\n",
       "      <td>110002</td>\n",
       "      <td>54.385737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.369882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182299</td>\n",
       "      <td>39.015855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182299</td>\n",
       "      <td>9.458389</td>\n",
       "      <td>2.338060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>110003</td>\n",
       "      <td>14.755792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.511583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.046333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.936520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.110972</td>\n",
       "      <td>110004</td>\n",
       "      <td>21.721631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.887150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.833229</td>\n",
       "      <td>106.052669</td>\n",
       "      <td>3.833229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.555486</td>\n",
       "      <td>5.110972</td>\n",
       "      <td>7.626311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.958055</td>\n",
       "      <td>110005</td>\n",
       "      <td>41.706387</td>\n",
       "      <td>5.958055</td>\n",
       "      <td>113.203051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.958055</td>\n",
       "      <td>95.328885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.958055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ÚLCERA_GÁSTRICA_E_DUODENAL  MUNCOD  \\\n",
       "0                   28.481914  110001   \n",
       "1                    9.458389  110002   \n",
       "2                    0.000000  110003   \n",
       "3                    5.110972  110004   \n",
       "4                    5.958055  110005   \n",
       "\n",
       "   VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES  VARICELA_E_HERPES_ZOSTER  \\\n",
       "0                                    40.688449                  0.000000   \n",
       "1                                    54.385737                  0.000000   \n",
       "2                                    14.755792                  0.000000   \n",
       "3                                    21.721631                  0.000000   \n",
       "4                                    41.706387                  5.958055   \n",
       "\n",
       "   UROLITÍASE  TÉTANO_NEONATAL  TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS  \\\n",
       "0  142.409570              NaN                                          NaN   \n",
       "1   15.369882              NaN                                          0.0   \n",
       "2   29.511583              NaN                                          NaN   \n",
       "3   63.887150              NaN                                          NaN   \n",
       "4  113.203051              NaN                                          NaN   \n",
       "\n",
       "   TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES  TUBERCULOSE_PULMONAR  \\\n",
       "0                                   NaN                   0.0   \n",
       "1                                   NaN                   0.0   \n",
       "2                                   NaN                   NaN   \n",
       "3                                   NaN                   0.0   \n",
       "4                                   NaN                   0.0   \n",
       "\n",
       "   TUBERCULOSE_MILIAR  ...  ANCILOSTOMÍASE  AMEBÍASE  \\\n",
       "0                 NaN  ...             NaN       0.0   \n",
       "1                 0.0  ...             NaN       0.0   \n",
       "2                 NaN  ...             NaN       NaN   \n",
       "3                 0.0  ...             NaN       NaN   \n",
       "4                 NaN  ...             NaN       NaN   \n",
       "\n",
       "   ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO  \\\n",
       "0                                                NaN    \n",
       "1                                                0.0    \n",
       "2                                                NaN    \n",
       "3                                                0.0    \n",
       "4                                                NaN    \n",
       "\n",
       "   AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT  \\\n",
       "0                                          44.757293   \n",
       "1                                           1.182299   \n",
       "2                                           0.000000   \n",
       "3                                           3.833229   \n",
       "4                                           5.958055   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM  \\\n",
       "0                                          40.688449   \n",
       "1                                          39.015855   \n",
       "2                                         118.046333   \n",
       "3                                         106.052669   \n",
       "4                                          95.328885   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL  \\\n",
       "0                                          32.550759    \n",
       "1                                           0.000000    \n",
       "2                                           0.000000    \n",
       "3                                           3.833229    \n",
       "4                                           0.000000    \n",
       "\n",
       "   ABORTO_POR_RAZÕES_MÉDICAS  ABORTO_ESPONTÂNEO   PREVIOUS       RATE  \n",
       "0                        NaN         126.134191  20.344224   8.212203  \n",
       "1                        0.0           1.182299   9.458389   2.338060  \n",
       "2                        NaN                NaN   0.000000  14.936520  \n",
       "3                        0.0           2.555486   5.110972   7.626311  \n",
       "4                        0.0           5.958055   0.000000   0.000000  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(years)-1):\n",
    "    col_year_suicide = \"RATE_\" + years[i+1]\n",
    "    col_year_prev = \"RATE_\" + years[i]\n",
    "    year_df = suicide[[col_year_prev, col_year_suicide, \"MUNCOD\"]]\n",
    "    year_df = year_df.rename(columns={col_year_suicide: \"RATE\"})\n",
    "    year_df = year_df.rename(columns={col_year_prev: \"PREVIOUS\"})\n",
    "    for disease in disease_list:\n",
    "        col_year_disease = \"RATE_\" + years[i]\n",
    "        disease_df = pd.read_csv(path + disease + \".csv\", sep=',', index_col=0)\n",
    "        disease_df = disease_df[[col_year_disease, \"MUNCOD\"]]\n",
    "        disease_df = disease_df.rename(columns={col_year_disease: disease})\n",
    "\n",
    "        year_df = pd.merge(disease_df, year_df, left_on=\"MUNCOD\", right_on=\"MUNCOD\", how='right')\n",
    "        \n",
    "    final_df = pd.concat([final_df, year_df])\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get UF from MUNCOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÚLCERA_GÁSTRICA_E_DUODENAL</th>\n",
       "      <th>VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES</th>\n",
       "      <th>VARICELA_E_HERPES_ZOSTER</th>\n",
       "      <th>UROLITÍASE</th>\n",
       "      <th>TÉTANO_NEONATAL</th>\n",
       "      <th>TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS</th>\n",
       "      <th>TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES</th>\n",
       "      <th>TUBERCULOSE_PULMONAR</th>\n",
       "      <th>TUBERCULOSE_MILIAR</th>\n",
       "      <th>TUBERCULOSE_DO_SISTEMA_NERVOSO</th>\n",
       "      <th>...</th>\n",
       "      <th>PR</th>\n",
       "      <th>RJ</th>\n",
       "      <th>RN</th>\n",
       "      <th>RO</th>\n",
       "      <th>RR</th>\n",
       "      <th>RS</th>\n",
       "      <th>SC</th>\n",
       "      <th>SE</th>\n",
       "      <th>SP</th>\n",
       "      <th>TO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.481914</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142.409570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.458389</td>\n",
       "      <td>54.385737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.369882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.755792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.511583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.110972</td>\n",
       "      <td>21.721631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.887150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.958055</td>\n",
       "      <td>41.706387</td>\n",
       "      <td>5.958055</td>\n",
       "      <td>113.203051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ÚLCERA_GÁSTRICA_E_DUODENAL  VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES  \\\n",
       "0                   28.481914                                    40.688449   \n",
       "1                    9.458389                                    54.385737   \n",
       "2                    0.000000                                    14.755792   \n",
       "3                    5.110972                                    21.721631   \n",
       "4                    5.958055                                    41.706387   \n",
       "\n",
       "   VARICELA_E_HERPES_ZOSTER  UROLITÍASE  TÉTANO_NEONATAL  \\\n",
       "0                  0.000000  142.409570              NaN   \n",
       "1                  0.000000   15.369882              NaN   \n",
       "2                  0.000000   29.511583              NaN   \n",
       "3                  0.000000   63.887150              NaN   \n",
       "4                  5.958055  113.203051              NaN   \n",
       "\n",
       "   TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS  \\\n",
       "0                                          NaN   \n",
       "1                                          0.0   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "   TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES  TUBERCULOSE_PULMONAR  \\\n",
       "0                                   NaN                   0.0   \n",
       "1                                   NaN                   0.0   \n",
       "2                                   NaN                   NaN   \n",
       "3                                   NaN                   0.0   \n",
       "4                                   NaN                   0.0   \n",
       "\n",
       "   TUBERCULOSE_MILIAR  TUBERCULOSE_DO_SISTEMA_NERVOSO  ...  PR  RJ  RN  RO  \\\n",
       "0                 NaN                             0.0  ...   0   0   0   1   \n",
       "1                 0.0                             NaN  ...   0   0   0   1   \n",
       "2                 NaN                             NaN  ...   0   0   0   1   \n",
       "3                 0.0                             NaN  ...   0   0   0   1   \n",
       "4                 NaN                             NaN  ...   0   0   0   1   \n",
       "\n",
       "   RR  RS  SC  SE  SP  TO  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 342 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['UF'] = final_df['MUNCOD'] / 10000\n",
    "final_df['UF'] = final_df['UF'].astype(int)\n",
    "final_df['UF'].replace(dict_uf_cod, inplace=True)\n",
    "dummy = pd.get_dummies(final_df['UF'])\n",
    "final_df = pd.concat([final_df, dummy], axis=1)\n",
    "final_df = final_df.drop(['MUNCOD', 'UF'], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before null values drop: (53810, 342)\n",
      "Minimum non-null values: 273/342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11920, 341)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_valid_values = 0.8\n",
    "num_feat = 50\n",
    "corr_min_value = 0.05\n",
    "\n",
    "print(\"Shape before null values drop:\", final_df.shape)\n",
    "N = int(final_df.shape[1]*percentage_valid_values)\n",
    "print(\"Minimum non-null values: \" + str(N) + \"/\" + str(final_df.shape[1]))\n",
    "final_zeros_df = final_df.dropna(thresh=N) # At least N non null items\n",
    "\n",
    "final_zeros_df = final_zeros_df[(np.abs(stats.zscore(final_zeros_df[\"RATE\"])) < 3)] # Remove outliers\n",
    "\n",
    "X = final_zeros_df.drop(columns=\"RATE\")\n",
    "X = X.fillna(0)\n",
    "y = final_zeros_df[\"RATE\"]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcUpMetrics(y_pred,y_test,X_test):\n",
    "    up_df = pd.DataFrame({\"Pred\": y_pred, \"Real\": y_test, \"Previous\": X_test[\"PREVIOUS\"]})\n",
    "    up_df[\"UP\"] = up_df[\"Previous\"] < up_df[\"Real\"]\n",
    "    up_df[\"UP_PRED\"] = up_df[\"Previous\"] < up_df[\"Pred\"]\n",
    "    up_df[\"UP\"] = up_df[\"UP\"].astype(int)\n",
    "    up_df[\"UP_PRED\"] = up_df[\"UP_PRED\"].astype(int)\n",
    "    return metrics.recall_score(up_df[\"UP\"], up_df[\"UP_PRED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_feat_importance(feature_importance_list):\n",
    "    final_feat_df = pd.DataFrame()\n",
    "    for i, feat_df in enumerate(feature_importance_list):\n",
    "        feat_df = feat_df.rename(columns={\"Importance\": i})\n",
    "        if final_feat_df.empty:\n",
    "            final_feat_df = feat_df\n",
    "        else:\n",
    "            final_feat_df = pd.merge(final_feat_df, feat_df, on=\"Feature\")\n",
    "    final_feat_df[\"Avg_importance\"] = final_feat_df.sum(axis=1)/(final_feat_df.shape[1] -1)\n",
    "    final_feat_df = final_feat_df[[\"Feature\", \"Avg_importance\"]]\n",
    "    return final_feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_feature_selector(X,y,corr_min_value):\n",
    "    cor_list = []\n",
    "    for i in list(X.columns):\n",
    "        cor = np.corrcoef(X[i], y)[0,1]\n",
    "        cor_list.append([i, cor])\n",
    "    cor_feature = [x[0] for x in cor_list if abs(x[1]) > corr_min_value]\n",
    "    print(len(cor_feature), \"selected features (correlation)\")\n",
    "    return cor_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## 1. Tree Models\n",
    "\n",
    "### 1.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== RUN 1 ===============\n",
      "# Feature Selection: correlation\n",
      "121 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.8706874725355613\n",
      "RMSE Test: 4.5559191861286665\n",
      "RMSE Baseline Train: 5.587001133045161\n",
      "RMSE Baseline Test: 5.708701552449413\n",
      "Up/Down Recall Train: 0.9659304511278195\n",
      "Up/Down Recall Test: 0.8090737240075614\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 2 ===============\n",
      "# Feature Selection: correlation\n",
      "111 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.8741405315300752\n",
      "RMSE Test: 4.272846119610831\n",
      "RMSE Baseline Train: 5.6053569012030104\n",
      "RMSE Baseline Test: 5.636266148619417\n",
      "Up/Down Recall Train: 0.970311027332705\n",
      "Up/Down Recall Test: 0.811214953271028\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 3 ===============\n",
      "# Feature Selection: correlation\n",
      "119 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.8334931899865756\n",
      "RMSE Test: 4.483437446593925\n",
      "RMSE Baseline Train: 5.631034413192984\n",
      "RMSE Baseline Test: 5.532938261654057\n",
      "Up/Down Recall Train: 0.9707122774133083\n",
      "Up/Down Recall Test: 0.8107074569789675\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 4 ===============\n",
      "# Feature Selection: correlation\n",
      "119 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.886950594204161\n",
      "RMSE Test: 4.417378947187657\n",
      "RMSE Baseline Train: 5.632256148839671\n",
      "RMSE Baseline Test: 5.527961898653148\n",
      "Up/Down Recall Train: 0.970285446888161\n",
      "Up/Down Recall Test: 0.8028846153846154\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 5 ===============\n",
      "# Feature Selection: correlation\n",
      "111 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.9023939413875144\n",
      "RMSE Test: 4.255800710073397\n",
      "RMSE Baseline Train: 5.60197594767346\n",
      "RMSE Baseline Test: 5.649695742629174\n",
      "Up/Down Recall Train: 0.9679639297579496\n",
      "Up/Down Recall Test: 0.8163636363636364\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== SUMMARY ===============\n",
      "# Average Metrics\n",
      "rmse_train             1.873533\n",
      "rmse_test              4.397076\n",
      "rmse_baseline_train    5.611525\n",
      "rmse_baseline_test     5.611113\n",
      "up_down_train          0.969041\n",
      "up_down_test           0.810049\n",
      "dtype: float64\n",
      "# Average Feature Importance\n",
      "                                              Feature  Avg_importance\n",
      "0                                            PREVIOUS        0.112572\n",
      "1   BRONQUITE_ENFISEMA_E_OUTR_DOENÇ_PULM_OBSTR_CRÔNIC        0.024084\n",
      "2                                                  RS        0.031217\n",
      "3                                 DOENÇAS_DO_APÊNDICE        0.014951\n",
      "4   NEOPLASIA_MALIGNA_DE_TRAQUÉIA_BRÔNQUIOS_E_PULMÕES        0.014621\n",
      "5                     TRANSTORNOS_DE_HUMOR_[AFETIVOS]        0.012151\n",
      "6       TRANSTORNOS_DE_CONDUÇÃO_E_ARRITMIAS_CARDÍACAS        0.017205\n",
      "7                           COLELITÍASE_E_COLECISTITE        0.012358\n",
      "8                  OUTRAS_NEOPLASIAS_MALIGNAS_DA_PELE        0.012978\n",
      "9   TRANST_MENTAIS_COMPORT_DEV_USO_OUTR_SUBST_PSICOAT        0.012484\n",
      "10          OUTRAS_DOENÇAS_DOS_INTESTINOS_E_PERITÔNIO        0.011179\n",
      "11                                         UROLITÍASE        0.011897\n",
      "12                             PARTO_ÚNICO_ESPONTÂNEO        0.011091\n",
      "13               OUTRAS_DOENÇAS_ISQUÊMICAS_DO_CORAÇÃO        0.011845\n",
      "14  TRANST_MENTAIS_E_COMPORTAMENTAIS_DEV_USO_DE_ÁL...        0.010691\n",
      "15                     OUTROS_TRANSTRONOS_ARTICULARES        0.009111\n",
      "16                                     OUTRAS_HÉRNIAS        0.010811\n",
      "17  NEOPL_MALIG_OUTR_LOCALIZ_MAL_DEF_SECUN_E_NÃO_E...        0.010593\n",
      "18                                 LEIOMIOMA_DO_ÚTERO        0.009932\n",
      "19     PANCREATITE_AGUDA_E_OUTRAS_DOENÇAS_DO_PÂNCREAS        0.009932\n",
      "\n",
      "Total run time: 6180.881489515305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "feature_importance_list = []\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        n_estimators = params[0]\n",
    "        max_depth = params[1]\n",
    "        min_samples_leaf = params[2]\n",
    "        max_features = params[3]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=n_estimators, \n",
    "                                      max_depth=max_depth,min_samples_leaf=min_samples_leaf,max_features=max_features)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (5,1000), #n_estimators\n",
    "        (3,30), #max_depth\n",
    "        (2,200), #min_samples_leaf\n",
    "        (0.25,1.00) #max_features\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=resultado_gp.x[0], \n",
    "                                  max_depth=resultado_gp.x[1],min_samples_leaf=resultado_gp.x[2],max_features=resultado_gp.x[3])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Recall Train:\", up_down_train)\n",
    "    print(\"Up/Down Recall Test:\", up_down_test)\n",
    "    scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "    \n",
    "    print(\"# Get Feature Importance\")\n",
    "    importance = regressor.feature_importances_\n",
    "    feature_importance_list.append(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "print(\"# Average Feature Importance\")\n",
    "final_feat_df = get_average_feat_importance(feature_importance_list)\n",
    "print(final_feat_df.head(20))\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "feature_importance_list = []\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        n_estimators = params[0]\n",
    "        learning_rate = params[1]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = AdaBoostRegressor(random_state=42,n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (30,200), #n_estimators\n",
    "        (0.01, 1) #learning_rate\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = AdaBoostRegressor(random_state=42,n_estimators=resultado_gp.x[0], learning_rate=resultado_gp.x[1])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Recall Train:\", up_down_train)\n",
    "    print(\"Up/Down Recall Test:\", up_down_test)\n",
    "    scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "    \n",
    "    print(\"# Get Feature Importance\")\n",
    "    importance = regressor.feature_importances_\n",
    "    feature_importance_list.append(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "print(\"# Average Feature Importance\")\n",
    "final_feat_df = get_average_feat_importance(feature_importance_list)\n",
    "print(final_feat_df.head(20))\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "feature_importance_list = []\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        n_estimators = params[0]\n",
    "        learning_rate = params[1]\n",
    "        max_depth = params[2]\n",
    "        min_samples_splits = params[3]\n",
    "        min_samples_leafs = params[4]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = GradientBoostingRegressor(random_state=42,n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "                                          max_depth=max_depth,min_samples_splits=min_samples_splits,min_samples_leafs=min_samples_leafs)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (30,200), #n_estimators\n",
    "        (0.01, 1), #learning_rate\n",
    "        (1,32), #max_depth\n",
    "        (0.1, 1) #min_samples_splits \n",
    "        (0.1, 0.5) #min_samples_leafs \n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = GradientBoostingRegressor(random_state=42,n_estimators=resultado_gp.x[0], learning_rate=resultado_gp.x[1],\n",
    "                                         max_depth=resultado_gp.x[2], min_samples_splits=resultado_gp.x[3], min_samples_leafs=resultado_gp.x[4])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Recall Train:\", up_down_train)\n",
    "    print(\"Up/Down Recall Test:\", up_down_test)\n",
    "    scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "    \n",
    "    print(\"# Get Feature Importance\")\n",
    "    importance = regressor.feature_importances_\n",
    "    feature_importance_list.append(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "print(\"# Average Feature Importance\")\n",
    "final_feat_df = get_average_feat_importance(feature_importance_list)\n",
    "print(final_feat_df.head(20))\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = MinMaxScaler()\n",
    "sc = StandardScaler()\n",
    "X_mm = mm.fit_transform(X)\n",
    "X_sc = sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== RUN 1 ===============\n",
      "# Feature Selection: correlation\n",
      "121 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 4.323473803754211\n",
      "RMSE Test: 4.574866137649635\n",
      "RMSE Baseline Train: 7.786216317996309\n",
      "RMSE Baseline Test: 7.890644139939839\n",
      "Up/Down Recall Train: 1.0\n",
      "Up/Down Recall Test: 1.0\n",
      "\n",
      "\n",
      "=============== RUN 2 ===============\n",
      "# Feature Selection: correlation\n",
      "111 selected features (correlation)\n",
      "# Bayesian Optimization\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-47f267117a56>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#C\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     ]\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mresultado_gp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_random_starts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"# Fitting the model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\skopt\\optimizer\\gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 268\u001b[1;33m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\skopt\\optimizer\\base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[1;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 301\u001b[1;33m         \u001b[0mnext_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    302\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-47f267117a56>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxf_train_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myf_train_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0myf_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxf_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myf_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myf_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ML\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 357\u001b[1;33m             cache_size=self.cache_size)\n\u001b[0m\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "count = 1\n",
    "\n",
    "X = pd.DataFrame(X_mm, index=X.index, columns=X.columns)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        gamma = params[0]\n",
    "        C = params[1]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = SVR(gamma=gamma, C=C)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (0.001,0.9), #gamma\n",
    "        (1,10000), #C\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = SVR(gamma=resultado_gp.x[0], C=resultado_gp.x[1])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Recall Train:\", up_down_train)\n",
    "    print(\"Up/Down Recall Test:\", up_down_test)\n",
    "    scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "count = 1\n",
    "\n",
    "X = pd.DataFrame(X_sc, index=X.index, columns=X.columns)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        gamma = params[0]\n",
    "        C = params[1]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = SVR(gamma=gamma, C=C)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (0.001,0.9), #gamma\n",
    "        (1,10000), #C\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = SVR(gamma=resultado_gp.x[0], C=resultado_gp.x[1])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Recall Train:\", up_down_train)\n",
    "    print(\"Up/Down Recall Test:\", up_down_test)\n",
    "    scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "count = 1\n",
    "\n",
    "X = pd.DataFrame(X_mm, index=X.index, columns=X.columns)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        alpha = params[0]\n",
    "        l1_ratio = params[1]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = ElasticNet(random_state=42,alpha=alpha, l1_ratio=l1_ratio)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (1,20), #alpha\n",
    "        (0,1), #l1_ratio\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = ElasticNet(random_state=42, alpha=resultado_gp.x[0], l1_ratio=resultado_gp.x[1])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Recall Train:\", up_down_train)\n",
    "    print(\"Up/Down Recall Test:\", up_down_test)\n",
    "    scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
