{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "Features = rates from selected diseases (FeatureSelection) + suicide rate \n",
    "\n",
    "Target = suicide rate of the following year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skopt import gp_minimize\n",
    "import glob\n",
    "root = \"../../\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_uf_cod = {11: 'RO',\n",
    "12: 'AC',\n",
    "13: 'AM',\n",
    "14: 'RR',\n",
    "15: 'PA',\n",
    "16: 'AP',\n",
    "17: 'TO',\n",
    "21: 'MA',\n",
    "22: 'PI',\n",
    "23: 'CE',\n",
    "24: 'RN',\n",
    "25: 'PB',\n",
    "26: 'PE',\n",
    "27: 'AL',\n",
    "28: 'SE',\n",
    "29: 'BA',\n",
    "31: 'MG',\n",
    "32: 'ES',\n",
    "33: 'RJ',\n",
    "35: 'SP',\n",
    "41: 'PR',\n",
    "42: 'SC',\n",
    "43: 'RS',\n",
    "50: 'MS',\n",
    "51: 'MT',\n",
    "52: 'GO',\n",
    "53: 'DF'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313  diseases\n"
     ]
    }
   ],
   "source": [
    "disease = \"\"\n",
    "path = root + \"CSV/TabNet/Internacoes_Rate/\"\n",
    "all_files = glob.glob(path + \"*.csv\")\n",
    "suicide = pd.read_csv(root +'CSV/Suicide/suicide_rates_08_18.csv', index_col=0)\n",
    "\n",
    "years = [str(x).zfill(2) for x in range(8,19)]\n",
    "columns = [\"RATE_\" + year for year in years]\n",
    "columns.append(\"MUNCOD\")\n",
    "\n",
    "disease_list = []\n",
    "\n",
    "for file in all_files:\n",
    "    file_name = file.split(\"\\\\\")[-1]\n",
    "    disease = file_name.split(\".csv\")[0]\n",
    "    disease_df = pd.read_csv(file, sep=',', index_col=0)\n",
    "    if(set(disease_df.columns) == set(columns)):\n",
    "        disease_list.append(disease)\n",
    "print(len(disease_list), \" diseases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÚLCERA_GÁSTRICA_E_DUODENAL</th>\n",
       "      <th>MUNCOD</th>\n",
       "      <th>VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES</th>\n",
       "      <th>VARICELA_E_HERPES_ZOSTER</th>\n",
       "      <th>UROLITÍASE</th>\n",
       "      <th>TÉTANO_NEONATAL</th>\n",
       "      <th>TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS</th>\n",
       "      <th>TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES</th>\n",
       "      <th>TUBERCULOSE_PULMONAR</th>\n",
       "      <th>TUBERCULOSE_MILIAR</th>\n",
       "      <th>...</th>\n",
       "      <th>ANCILOSTOMÍASE</th>\n",
       "      <th>AMEBÍASE</th>\n",
       "      <th>ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO</th>\n",
       "      <th>AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM</th>\n",
       "      <th>ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL</th>\n",
       "      <th>ABORTO_POR_RAZÕES_MÉDICAS</th>\n",
       "      <th>ABORTO_ESPONTÂNEO</th>\n",
       "      <th>PREVIOUS</th>\n",
       "      <th>RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.481914</td>\n",
       "      <td>110001</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142.409570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.757293</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>32.550759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126.134191</td>\n",
       "      <td>20.344224</td>\n",
       "      <td>8.212203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.458389</td>\n",
       "      <td>110002</td>\n",
       "      <td>54.385737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.369882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182299</td>\n",
       "      <td>39.015855</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.182299</td>\n",
       "      <td>9.458389</td>\n",
       "      <td>2.338060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>110003</td>\n",
       "      <td>14.755792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.511583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>118.046333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.936520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.110972</td>\n",
       "      <td>110004</td>\n",
       "      <td>21.721631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.887150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.833229</td>\n",
       "      <td>106.052669</td>\n",
       "      <td>3.833229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.555486</td>\n",
       "      <td>5.110972</td>\n",
       "      <td>7.626311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.958055</td>\n",
       "      <td>110005</td>\n",
       "      <td>41.706387</td>\n",
       "      <td>5.958055</td>\n",
       "      <td>113.203051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.958055</td>\n",
       "      <td>95.328885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.958055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 316 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ÚLCERA_GÁSTRICA_E_DUODENAL  MUNCOD  \\\n",
       "0                   28.481914  110001   \n",
       "1                    9.458389  110002   \n",
       "2                    0.000000  110003   \n",
       "3                    5.110972  110004   \n",
       "4                    5.958055  110005   \n",
       "\n",
       "   VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES  VARICELA_E_HERPES_ZOSTER  \\\n",
       "0                                    40.688449                  0.000000   \n",
       "1                                    54.385737                  0.000000   \n",
       "2                                    14.755792                  0.000000   \n",
       "3                                    21.721631                  0.000000   \n",
       "4                                    41.706387                  5.958055   \n",
       "\n",
       "   UROLITÍASE  TÉTANO_NEONATAL  TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS  \\\n",
       "0  142.409570              NaN                                          NaN   \n",
       "1   15.369882              NaN                                          0.0   \n",
       "2   29.511583              NaN                                          NaN   \n",
       "3   63.887150              NaN                                          NaN   \n",
       "4  113.203051              NaN                                          NaN   \n",
       "\n",
       "   TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES  TUBERCULOSE_PULMONAR  \\\n",
       "0                                   NaN                   0.0   \n",
       "1                                   NaN                   0.0   \n",
       "2                                   NaN                   NaN   \n",
       "3                                   NaN                   0.0   \n",
       "4                                   NaN                   0.0   \n",
       "\n",
       "   TUBERCULOSE_MILIAR  ...  ANCILOSTOMÍASE  AMEBÍASE  \\\n",
       "0                 NaN  ...             NaN       0.0   \n",
       "1                 0.0  ...             NaN       0.0   \n",
       "2                 NaN  ...             NaN       NaN   \n",
       "3                 0.0  ...             NaN       NaN   \n",
       "4                 NaN  ...             NaN       NaN   \n",
       "\n",
       "   ALGUNS_TRANSTORNOS_ENVOLVENDO_MECANISMO_IMUNITÁRIO  \\\n",
       "0                                                NaN    \n",
       "1                                                0.0    \n",
       "2                                                NaN    \n",
       "3                                                0.0    \n",
       "4                                                NaN    \n",
       "\n",
       "   AFECÇ_HEMORRÁG_E_OUTR_DOENÇ_SANG_E_ÓRG_HEMATOPOÉT  \\\n",
       "0                                          44.757293   \n",
       "1                                           1.182299   \n",
       "2                                           0.000000   \n",
       "3                                           3.833229   \n",
       "4                                           5.958055   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_NÃO_ESPEC_HEMORRÁG_OU_ISQUÊM  \\\n",
       "0                                          40.688449   \n",
       "1                                          39.015855   \n",
       "2                                         118.046333   \n",
       "3                                         106.052669   \n",
       "4                                          95.328885   \n",
       "\n",
       "   ACID_VASCULAR_CEREBR_ISQUÊM_TRANSIT_E_SÍNDR_CORREL  \\\n",
       "0                                          32.550759    \n",
       "1                                           0.000000    \n",
       "2                                           0.000000    \n",
       "3                                           3.833229    \n",
       "4                                           0.000000    \n",
       "\n",
       "   ABORTO_POR_RAZÕES_MÉDICAS  ABORTO_ESPONTÂNEO   PREVIOUS       RATE  \n",
       "0                        NaN         126.134191  20.344224   8.212203  \n",
       "1                        0.0           1.182299   9.458389   2.338060  \n",
       "2                        NaN                NaN   0.000000  14.936520  \n",
       "3                        0.0           2.555486   5.110972   7.626311  \n",
       "4                        0.0           5.958055   0.000000   0.000000  \n",
       "\n",
       "[5 rows x 316 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = pd.DataFrame()\n",
    "\n",
    "for i in range(len(years)-1):\n",
    "    col_year_suicide = \"RATE_\" + years[i+1]\n",
    "    col_year_prev = \"RATE_\" + years[i]\n",
    "    year_df = suicide[[col_year_prev, col_year_suicide, \"MUNCOD\"]]\n",
    "    year_df = year_df.rename(columns={col_year_suicide: \"RATE\"})\n",
    "    year_df = year_df.rename(columns={col_year_prev: \"PREVIOUS\"})\n",
    "    for disease in disease_list:\n",
    "        col_year_disease = \"RATE_\" + years[i]\n",
    "        disease_df = pd.read_csv(path + disease + \".csv\", sep=',', index_col=0)\n",
    "        disease_df = disease_df[[col_year_disease, \"MUNCOD\"]]\n",
    "        disease_df = disease_df.rename(columns={col_year_disease: disease})\n",
    "\n",
    "        year_df = pd.merge(disease_df, year_df, left_on=\"MUNCOD\", right_on=\"MUNCOD\", how='right')\n",
    "        \n",
    "    final_df = pd.concat([final_df, year_df])\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get UF from MUNCOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ÚLCERA_GÁSTRICA_E_DUODENAL</th>\n",
       "      <th>VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES</th>\n",
       "      <th>VARICELA_E_HERPES_ZOSTER</th>\n",
       "      <th>UROLITÍASE</th>\n",
       "      <th>TÉTANO_NEONATAL</th>\n",
       "      <th>TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS</th>\n",
       "      <th>TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES</th>\n",
       "      <th>TUBERCULOSE_PULMONAR</th>\n",
       "      <th>TUBERCULOSE_MILIAR</th>\n",
       "      <th>TUBERCULOSE_DO_SISTEMA_NERVOSO</th>\n",
       "      <th>...</th>\n",
       "      <th>PR</th>\n",
       "      <th>RJ</th>\n",
       "      <th>RN</th>\n",
       "      <th>RO</th>\n",
       "      <th>RR</th>\n",
       "      <th>RS</th>\n",
       "      <th>SC</th>\n",
       "      <th>SE</th>\n",
       "      <th>SP</th>\n",
       "      <th>TO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.481914</td>\n",
       "      <td>40.688449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142.409570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.458389</td>\n",
       "      <td>54.385737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.369882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.755792</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.511583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.110972</td>\n",
       "      <td>21.721631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.887150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.958055</td>\n",
       "      <td>41.706387</td>\n",
       "      <td>5.958055</td>\n",
       "      <td>113.203051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ÚLCERA_GÁSTRICA_E_DUODENAL  VEIAS_VARICOSAS_DAS_EXTREMIDADES_INFERIORES  \\\n",
       "0                   28.481914                                    40.688449   \n",
       "1                    9.458389                                    54.385737   \n",
       "2                    0.000000                                    14.755792   \n",
       "3                    5.110972                                    21.721631   \n",
       "4                    5.958055                                    41.706387   \n",
       "\n",
       "   VARICELA_E_HERPES_ZOSTER  UROLITÍASE  TÉTANO_NEONATAL  \\\n",
       "0                  0.000000  142.409570              NaN   \n",
       "1                  0.000000   15.369882              NaN   \n",
       "2                  0.000000   29.511583              NaN   \n",
       "3                  0.000000   63.887150              NaN   \n",
       "4                  5.958055  113.203051              NaN   \n",
       "\n",
       "   TUBERC_INTEST_PERITÔNIO_GLÂNGL_MESENTÉRICOS  \\\n",
       "0                                          NaN   \n",
       "1                                          0.0   \n",
       "2                                          NaN   \n",
       "3                                          NaN   \n",
       "4                                          NaN   \n",
       "\n",
       "   TUBERCULOSE_ÓSSEA_E_DAS_ARTICULAÇÕES  TUBERCULOSE_PULMONAR  \\\n",
       "0                                   NaN                   0.0   \n",
       "1                                   NaN                   0.0   \n",
       "2                                   NaN                   NaN   \n",
       "3                                   NaN                   0.0   \n",
       "4                                   NaN                   0.0   \n",
       "\n",
       "   TUBERCULOSE_MILIAR  TUBERCULOSE_DO_SISTEMA_NERVOSO  ...  PR  RJ  RN  RO  \\\n",
       "0                 NaN                             0.0  ...   0   0   0   1   \n",
       "1                 0.0                             NaN  ...   0   0   0   1   \n",
       "2                 NaN                             NaN  ...   0   0   0   1   \n",
       "3                 0.0                             NaN  ...   0   0   0   1   \n",
       "4                 NaN                             NaN  ...   0   0   0   1   \n",
       "\n",
       "   RR  RS  SC  SE  SP  TO  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 342 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['UF'] = final_df['MUNCOD'] / 10000\n",
    "final_df['UF'] = final_df['UF'].astype(int)\n",
    "final_df['UF'].replace(dict_uf_cod, inplace=True)\n",
    "dummy = pd.get_dummies(final_df['UF'])\n",
    "final_df = pd.concat([final_df, dummy], axis=1)\n",
    "final_df = final_df.drop(['MUNCOD', 'UF'], axis=1)\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before null values drop: (53810, 342)\n",
      "Minimum non-null values: 273/342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11920, 341)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentage_valid_values = 0.8\n",
    "num_feat = 50\n",
    "corr_min_value = 0.05\n",
    "\n",
    "print(\"Shape before null values drop:\", final_df.shape)\n",
    "N = int(final_df.shape[1]*percentage_valid_values)\n",
    "print(\"Minimum non-null values: \" + str(N) + \"/\" + str(final_df.shape[1]))\n",
    "final_zeros_df = final_df.dropna(thresh=N) # At least N non null items\n",
    "\n",
    "X = final_zeros_df.drop(columns=\"RATE\")\n",
    "X = X.fillna(0)\n",
    "y = final_zeros_df[\"RATE\"]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcUpMetrics(y_pred,y_test,X_test):\n",
    "    up_df = pd.DataFrame({\"Pred\": y_pred, \"Real\": y_test, \"Previous\": X_test[\"PREVIOUS\"]})\n",
    "    up_df[\"UP\"] = up_df[\"Previous\"] < up_df[\"Real\"]\n",
    "    up_df[\"UP_PRED\"] = up_df[\"Previous\"] < up_df[\"Pred\"]\n",
    "    up_df[\"UP\"] = up_df[\"UP\"].astype(int)\n",
    "    up_df[\"UP_PRED\"] = up_df[\"UP_PRED\"].astype(int)\n",
    "    return metrics.accuracy_score(up_df[\"UP\"], up_df[\"UP_PRED\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_feat_importance(feature_importance_list):\n",
    "    final_feat_df = pd.DataFrame()\n",
    "    for i, feat_df in enumerate(feature_importance_list):\n",
    "        feat_df = feat_df.rename(columns={\"Importance\": i})\n",
    "        if final_feat_df.empty:\n",
    "            final_feat_df = feat_df\n",
    "        else:\n",
    "            final_feat_df = pd.merge(final_feat_df, feat_df, on=\"Feature\")\n",
    "    final_feat_df[\"Avg_importance\"] = final_feat_df.sum(axis=1)/(final_feat_df.shape[1] -1)\n",
    "    final_feat_df = final_feat_df[[\"Feature\", \"Avg_importance\"]]\n",
    "    return final_feat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_feature_selector(X,y,corr_min_value):\n",
    "    cor_list = []\n",
    "    for i in list(X.columns):\n",
    "        cor = np.corrcoef(X[i], y)[0,1]\n",
    "        cor_list.append([i, cor])\n",
    "    cor_feature = [x[0] for x in cor_list if abs(x[1]) > corr_min_value]\n",
    "    print(len(cor_feature), \"selected features (correlation)\")\n",
    "    return cor_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First model: no bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== RUN 1 ===============\n",
      "# Feature Selection: correlation\n",
      "121 selected features (correlation)\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.6427325700322828\n",
      "RMSE Test: 4.636173203018522\n",
      "RMSE Baseline Train: 5.587001133045161\n",
      "RMSE Baseline Test: 5.708701552449413\n",
      "Up/Down Accuracy Train: 0.8623112416107382\n",
      "Up/Down Accuracy Test: 0.6455536912751678\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 2 ===============\n",
      "# Feature Selection: correlation\n",
      "111 selected features (correlation)\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.689121384056114\n",
      "RMSE Test: 4.276097296046732\n",
      "RMSE Baseline Train: 5.6053569012030104\n",
      "RMSE Baseline Test: 5.636266148619417\n",
      "Up/Down Accuracy Train: 0.8622063758389261\n",
      "Up/Down Accuracy Test: 0.6661073825503355\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 3 ===============\n",
      "# Feature Selection: correlation\n",
      "119 selected features (correlation)\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.6532356731594455\n",
      "RMSE Test: 4.504012505864433\n",
      "RMSE Baseline Train: 5.631034413192984\n",
      "RMSE Baseline Test: 5.532938261654057\n",
      "Up/Down Accuracy Train: 0.8576971476510067\n",
      "Up/Down Accuracy Test: 0.6581375838926175\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 4 ===============\n",
      "# Feature Selection: correlation\n",
      "119 selected features (correlation)\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.6558986405272265\n",
      "RMSE Test: 4.500274088294989\n",
      "RMSE Baseline Train: 5.632256148839671\n",
      "RMSE Baseline Test: 5.527961898653148\n",
      "Up/Down Accuracy Train: 0.8604236577181208\n",
      "Up/Down Accuracy Test: 0.6556208053691275\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== RUN 5 ===============\n",
      "# Feature Selection: correlation\n",
      "111 selected features (correlation)\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.688394152465113\n",
      "RMSE Test: 4.326067989206846\n",
      "RMSE Baseline Train: 5.60197594767346\n",
      "RMSE Baseline Test: 5.649695742629174\n",
      "Up/Down Accuracy Train: 0.8585360738255033\n",
      "Up/Down Accuracy Test: 0.6816275167785235\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== SUMMARY ===============\n",
      "rmse_train             1.665876\n",
      "rmse_test              4.448525\n",
      "rmse_baseline_train    5.611525\n",
      "rmse_baseline_test     5.611113\n",
      "up_down_train          0.860235\n",
      "up_down_test           0.661409\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "feature_importance_list = []\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = RandomForestRegressor(random_state=42)\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Accuracy Train:\", up_down_train)\n",
    "    print(\"Up/Down Accuracy Test:\", up_down_test)\n",
    "    scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "    \n",
    "    print(\"# Get Feature Importance\")\n",
    "    importance = regressor.feature_importances_\n",
    "    feature_importance_list.append(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "print(\"# Average Feature Importance\")\n",
    "final_feat_df = get_average_feat_importance(feature_importance_list)\n",
    "print(final_feat_df.head(20))\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second model: with bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== RUN 1 ===============\n",
      "# Feature Selection: correlation\n",
      "121 selected features (correlation)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.8706874725355613\n",
      "RMSE Test: 4.5559191861286665\n",
      "RMSE Baseline Train: 5.587001133045161\n",
      "RMSE Baseline Test: 5.708701552449413\n",
      "Up/Down Accuracy Train: 0.8560192953020134\n",
      "Up/Down Accuracy Test: 0.6535234899328859\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== SUMMARY ===============\n",
      "rmse_train             1.870687\n",
      "rmse_test              4.555919\n",
      "rmse_baseline_train    5.587001\n",
      "rmse_baseline_test     5.708702\n",
      "up_down_train          0.856019\n",
      "up_down_test           0.653523\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "feature_importance_list = []\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    if(count > 1):\n",
    "        break # delete this later\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        n_estimators = params[0]\n",
    "        max_depth = params[1]\n",
    "        min_samples_leaf = params[2]\n",
    "        max_features = params[3]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=n_estimators, \n",
    "                                      max_depth=max_depth,min_samples_leaf=min_samples_leaf,max_features=max_features)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (5,1000), #n_estimators\n",
    "        (3,30), #max_depth\n",
    "        (2,200), #min_samples_leaf\n",
    "        (0.25,1.00) #max_features\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=resultado_gp.x[0], \n",
    "                                  max_depth=resultado_gp.x[1],min_samples_leaf=resultado_gp.x[2],max_features=resultado_gp.x[3])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Accuracy Train:\", up_down_train)\n",
    "    print(\"Up/Down Accuracy Test:\", up_down_test)\n",
    "    scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "    \n",
    "    print(\"# Get Feature Importance\")\n",
    "    importance = regressor.feature_importances_\n",
    "    feature_importance_list.append(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "print(\"# Average Feature Importance\")\n",
    "final_feat_df = get_average_feat_importance(feature_importance_list)\n",
    "print(final_feat_df.head(20))\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third model: with RFE feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfe_feature_selector(X,y,n_features_to_select):\n",
    "    rfe_selector = RFE(estimator=RandomForestRegressor(random_state=42), step=10, verbose=0,n_features_to_select=n_features_to_select)\n",
    "    rfe_selector.fit(X, y)\n",
    "    rfe_support = rfe_selector.get_support()\n",
    "    rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
    "    print(len(rfe_feature), 'selected features (RFE)')\n",
    "    return rfe_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== RUN 1 ===============\n",
      "# Feature Selection: correlation\n",
      "121 selected features (correlation)\n",
      "# Feature Selection: RFE\n",
      "50 selected features (RFE)\n",
      "# Bayesian Optimization\n",
      "# Fitting the model\n",
      "# Making predictions\n",
      "# Calculating metrics\n",
      "RMSE Train: 1.930398142725495\n",
      "RMSE Test: 4.570381192405489\n",
      "RMSE Baseline Train: 5.587001133045161\n",
      "RMSE Baseline Test: 5.708701552449413\n",
      "Up/Down Accuracy Train: 0.855494966442953\n",
      "Up/Down Accuracy Test: 0.6535234899328859\n",
      "# Get Feature Importance\n",
      "\n",
      "\n",
      "=============== SUMMARY ===============\n",
      "rmse_train             1.930398\n",
      "rmse_test              4.570381\n",
      "rmse_baseline_train    5.587001\n",
      "rmse_baseline_test     5.708702\n",
      "up_down_train          0.855495\n",
      "up_down_test           0.653523\n",
      "dtype: float64\n",
      "Total run time: 1549.431699514389\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "start = time.time()\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "scores = pd.DataFrame({\"rmse_train\": [], \"rmse_test\": [], \"rmse_baseline_train\": [], \"rmse_baseline_test\": [], \"up_down_train\": [], \"up_down_test\": []})\n",
    "feature_importance_list = []\n",
    "count = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    if(count > 1):\n",
    "        break # delete this later\n",
    "    print(\"=============== RUN {} ===============\".format(count))\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    print(\"# Feature Selection: correlation\")\n",
    "    selected_cor_features = cor_feature_selector(X_train,y_train,corr_min_value)\n",
    "    X_train = X_train[selected_cor_features]\n",
    "    X_test = X_test[selected_cor_features]\n",
    "    \n",
    "    print(\"# Feature Selection: RFE\")\n",
    "    selected_rfe_features = rfe_feature_selector(X_train,y_train,num_feat)\n",
    "    X_train = X_train[selected_rfe_features]\n",
    "    X_test = X_test[selected_rfe_features]\n",
    "    \n",
    "    print(\"# Bayesian Optimization\")\n",
    "    def train_model(params):\n",
    "        n_estimators = params[0]\n",
    "        max_depth = params[1]\n",
    "        min_samples_leaf = params[2]\n",
    "        max_features = params[3]\n",
    "\n",
    "        xf_train_params,xf_val,yf_train_params,yf_val = train_test_split(X_train,y_train,test_size=0.33,random_state=42)\n",
    "\n",
    "        model = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=n_estimators, \n",
    "                                      max_depth=max_depth,min_samples_leaf=min_samples_leaf,max_features=max_features)\n",
    "\n",
    "        model.fit(xf_train_params,yf_train_params)\n",
    "        yf_pred = model.predict(xf_val)\n",
    "\n",
    "        return np.sqrt(metrics.mean_squared_error(yf_val, yf_pred))\n",
    "    space = [\n",
    "        (5,1000), #n_estimators\n",
    "        (3,30), #max_depth\n",
    "        (2,200), #min_samples_leaf\n",
    "        (0.25,1.00) #max_features\n",
    "    ]\n",
    "    resultado_gp = gp_minimize(train_model, space, random_state=42, verbose=0, n_calls=30, n_random_starts=10)\n",
    "    \n",
    "    print(\"# Fitting the model\")\n",
    "    regressor = RandomForestRegressor(n_jobs=-1, random_state=42,n_estimators=resultado_gp.x[0], \n",
    "                                  max_depth=resultado_gp.x[1],min_samples_leaf=resultado_gp.x[2],max_features=resultado_gp.x[3])\n",
    "    regressor.fit(X_train,y_train)\n",
    "    \n",
    "    print(\"# Making predictions\")\n",
    "    y_pred = regressor.predict(X_test) \n",
    "    y_pred_train = regressor.predict(X_train)\n",
    "    \n",
    "    print(\"# Calculating metrics\")\n",
    "    rmse_train = np.sqrt(metrics.mean_squared_error(y_pred_train,y_train))\n",
    "    rmse_test = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "    rmse_baseline_train = np.sqrt(metrics.mean_squared_error(X_train[\"PREVIOUS\"],y_train))\n",
    "    rmse_baseline_test = np.sqrt(metrics.mean_squared_error(X_test[\"PREVIOUS\"],y_test))\n",
    "    up_down_train = calcUpMetrics(y_pred_train,y_train,X_train)\n",
    "    up_down_test = calcUpMetrics(y_pred,y_test,X_test)\n",
    "                                 \n",
    "    print(\"RMSE Train:\", rmse_train)\n",
    "    print(\"RMSE Test:\", rmse_test)\n",
    "    print(\"RMSE Baseline Train:\", rmse_baseline_train)\n",
    "    print(\"RMSE Baseline Test:\", rmse_baseline_test)\n",
    "    print(\"Up/Down Accuracy Train:\", up_down_train)\n",
    "    print(\"Up/Down Accuracy Test:\", up_down_test)\n",
    "    scores = scores.append({'rmse_train':rmse_train, 'rmse_test':rmse_test, \"rmse_baseline_train\": rmse_baseline_train, \"rmse_baseline_test\": rmse_baseline_test, \"up_down_train\": up_down_train, \"up_down_test\": up_down_test},ignore_index=True)\n",
    "    \n",
    "    print(\"# Get Feature Importance\")\n",
    "    importance = regressor.feature_importances_\n",
    "    feature_importance_list.append(pd.DataFrame({\"Feature\": X_train.columns, \"Importance\": importance}).sort_values(by=\"Importance\", ascending=False))\n",
    "    \n",
    "    print(\"\\n\")\n",
    "    count += 1\n",
    "print(\"=============== SUMMARY ===============\")\n",
    "print(\"# Average Metrics\")\n",
    "print(scores.mean())\n",
    "print(\"# Average Feature Importance\")\n",
    "final_feat_df = get_average_feat_importance(feature_importance_list)\n",
    "print(final_feat_df.head(20))\n",
    "end = time.time()\n",
    "\n",
    "print(\"\\nTotal run time:\", end-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
